{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant Data Science Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation and Formating Steps\n",
    "def random_crop(img, newdim ,width):\n",
    "    crop = np.random.randint(0,2,1)[0]\n",
    "    if crop == 1:\n",
    "        assert img.shape[0] >= width\n",
    "        assert img.shape[1] >= width\n",
    "        x = np.random.randint(0, img.shape[1] - width)\n",
    "        y = np.random.randint(0, img.shape[0] - width)\n",
    "        img = img[y:y+width, x:x+width]\n",
    "        img = cv2.resize(img, dsize=(newdim, newdim), interpolation = cv2.INTER_NEAREST)\n",
    "    else:\n",
    "        img = cv2.resize(img, dsize=(newdim, newdim), interpolation = cv2.INTER_NEAREST)\n",
    "    return img\n",
    "\n",
    "def image_process(images,newdim,augment):\n",
    "    #First Clean the Dataframes\n",
    "    rows = images.shape[0]\n",
    "    crop_width = np.random.randint(30,150,rows)\n",
    "    image_final = np.zeros(shape=(rows,newdim,newdim,3))\n",
    "    for i in range(rows):\n",
    "        if augment == True:\n",
    "            x = random_crop(images[i],newdim,crop_width[i])\n",
    "            x = np.array(x).reshape(newdim,newdim,1)\n",
    "            x = x.astype('float32') / 255\n",
    "        else: \n",
    "            x = cv2.resize(images[i], dsize=(newdim, newdim), interpolation = cv2.INTER_NEAREST)\n",
    "            x = np.array(x).reshape(newdim,newdim,1)\n",
    "            x = x.astype('float32') / 255\n",
    "        image_final[i] = cv2.cvtColor(x, cv2.COLOR_GRAY2RGB)\n",
    "    return image_final\n",
    "\n",
    "def data_process(filenames,path2dat,newdim,augment):\n",
    "    for file in filenames:\n",
    "        if 'images' in vars():\n",
    "            print(\"Processing:\" + file)\n",
    "            x = np.load(path2dat + file)\n",
    "            x = image_process(x,newdim,augment)\n",
    "            images = np.vstack((images,x))\n",
    "        else:\n",
    "            print(\"Processing:\" + file)\n",
    "            images = np.load(path2dat + file)\n",
    "            images = image_process(images,newdim,augment)\n",
    "        print(\"Current Size:\" + str(images.shape))\n",
    "    return images\n",
    "\n",
    "def labels_process(labelnames,path2dat):\n",
    "    for file in labelnames:\n",
    "        if 'labels' in vars():\n",
    "            print(\"Processing:\" + file)\n",
    "            x = np.load(path2dat + file)\n",
    "            labels = np.concatenate((labels,x))\n",
    "        else:\n",
    "            print(\"Processing:\" + file)\n",
    "            labels = np.load(path2dat + file)\n",
    "        print(\"Current Size:\" + str(labels.shape))\n",
    "    return labels\n",
    "\n",
    "def join_val_train(images,labels,path2dat,newdim):\n",
    "    im1 = np.load(path2dat + images[0])\n",
    "    im2 = np.load(path2dat + images[1])\n",
    "    im = np.vstack((im1,im2))    \n",
    "    del im1, im2\n",
    "    \n",
    "    lab1 = np.load(path2dat + labels[0])\n",
    "    lab2 = np.load(path2dat + labels[1])\n",
    "    lab = np.concatenate((lab1,lab2))\n",
    "    lab[lab > 0] = 1\n",
    "    del lab1, lab2\n",
    "    \n",
    "    im = image_process(im,newdim,augment=False)\n",
    "    \n",
    "    return im, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Train, Validation Data\n",
    "path2dat = \"C:/Users/alex/Hands-On-Machine Learning/Project - Mammography/Data/\"\n",
    "path2out = path2dat + \"/Processed/\"\n",
    "vt_im_files = [\"cv10_data.npy\",\"test10_data.npy\"]\n",
    "vt_lab_files = [\"cv10_labels.npy\",\"test10_labels.npy\"]\n",
    "\n",
    "vt_im, vt_lab = join_val_train(vt_im_files,vt_lab_files,path2dat,newdim=64)\n",
    "validation_images, test_images, validation_labels, test_labels = train_test_split(vt_im, vt_lab, test_size=0.5,stratify=vt_lab)\n",
    "np.save(path2out + \"Validation_Images.npy\",validation_images)\n",
    "np.save(path2out + \"Validation_Labels.npy\",validation_labels)\n",
    "np.save(path2out + \"Test_Images.npy\",test_images)\n",
    "np.save(path2out + \"Test_Labels.npy\",test_labels)\n",
    "del validation_images, test_images, validation_labels, test_labels,vt_im,vt_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:train_img_raw_0.npy\n",
      "Current Size:(11177, 64, 64, 3)\n",
      "Processing:train_img_raw_1.npy\n",
      "Current Size:(22354, 64, 64, 3)\n",
      "Processing:train_img_raw_2.npy\n",
      "Current Size:(33531, 64, 64, 3)\n",
      "Processing:train_img_raw_3.npy\n",
      "Current Size:(44708, 64, 64, 3)\n",
      "Processing:train_img_raw_4.npy\n",
      "Current Size:(55885, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#Process Raw Images\n",
    "path2dat = \"C:/Users/alex/Hands-On-Machine Learning/Project - Mammography/Data/\"\n",
    "path2out = path2dat + \"/Processed/\"\n",
    "filenames = [\"train_img_raw_0.npy\",\"train_img_raw_1.npy\",\"train_img_raw_2.npy\",\"train_img_raw_3.npy\",\"train_img_raw_4.npy\"]\n",
    "train_images = data_process(filenames,path2dat,64,False)\n",
    "np.save(path2out + \"Train_Images0.npy\",train_images)\n",
    "del train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:train_lab_raw_0.npy\n",
      "Current Size:(11177,)\n",
      "Processing:train_lab_raw_1.npy\n",
      "Current Size:(22354,)\n",
      "Processing:train_lab_raw_2.npy\n",
      "Current Size:(33531,)\n",
      "Processing:train_lab_raw_3.npy\n",
      "Current Size:(44708,)\n",
      "Processing:train_lab_raw_4.npy\n",
      "Current Size:(55885,)\n"
     ]
    }
   ],
   "source": [
    "#Process Training Labels (Raw)\n",
    "labelnames = [\"train_lab_raw_0.npy\",\"train_lab_raw_1.npy\",\"train_lab_raw_2.npy\",\"train_lab_raw_3.npy\",\"train_lab_raw_4.npy\"]\n",
    "train_labels = labels_process(labelnames,path2dat)\n",
    "np.save(path2out + \"Train_Labels0.npy\",train_labels)\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:train_img_aug_0.npy\n",
      "Current Size:(18572, 64, 64, 3)\n",
      "Processing:train_img_aug_1.npy\n",
      "Current Size:(36879, 64, 64, 3)\n",
      "Processing:train_img_aug_2.npy\n",
      "Current Size:(55276, 64, 64, 3)\n",
      "Processing:train_img_aug_3.npy\n",
      "Current Size:(74008, 64, 64, 3)\n",
      "Processing:train_img_aug_4.npy\n",
      "Current Size:(92405, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#Process Upscaled Images\n",
    "filenames = [\"train_img_aug_0.npy\",\"train_img_aug_1.npy\",\"train_img_aug_2.npy\",\"train_img_aug_3.npy\",\"train_img_aug_4.npy\"]\n",
    "train_images = data_process(filenames,path2dat,64,False)\n",
    "np.save(path2out + \"Train_Images1.npy\",train_images)\n",
    "del train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:train_lab_aug_0.npy\n",
      "Current Size:(18572,)\n",
      "Processing:train_lab_aug_1.npy\n",
      "Current Size:(36879,)\n",
      "Processing:train_lab_aug_2.npy\n",
      "Current Size:(55276,)\n",
      "Processing:train_lab_aug_3.npy\n",
      "Current Size:(74008,)\n",
      "Processing:train_lab_aug_4.npy\n",
      "Current Size:(92405,)\n"
     ]
    }
   ],
   "source": [
    "#Process Training Labels (Generic)\n",
    "labelnames = [\"train_lab_aug_0.npy\",\"train_lab_aug_1.npy\",\"train_lab_aug_2.npy\",\"train_lab_aug_3.npy\",\"train_lab_aug_4.npy\"]\n",
    "train_labels = labels_process(labelnames,path2dat)\n",
    "np.save(path2out + \"Train_Labels.npy\",train_labels)\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:train_img_aug_0.npy\n",
      "Current Size:(18572, 64, 64, 3)\n",
      "Processing:train_img_aug_1.npy\n",
      "Current Size:(36879, 64, 64, 3)\n",
      "Processing:train_img_aug_2.npy\n",
      "Current Size:(55276, 64, 64, 3)\n",
      "Processing:train_img_aug_3.npy\n",
      "Current Size:(74008, 64, 64, 3)\n",
      "Processing:train_img_aug_4.npy\n",
      "Current Size:(92405, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#Process Upscaled Images + Random Cropping\n",
    "train_images = data_process(filenames,path2dat,64,True)\n",
    "np.save(path2out + \"Train_Images2.npy\",train_images)\n",
    "del train_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
